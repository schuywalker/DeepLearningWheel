{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yahooquery\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CRITICAL TODO: \n",
    "shuffle windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the problem with most LSTM based stock price prediction is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get previous quarters open and close prices\n",
    "# never use same data twice\n",
    "# always use data from before more than 1 month ago\n",
    "# 3 months for a sample, predict 1 month. This gives us 4 samples per ticker per year.\n",
    "# easiest additional feature to add right now is volume. 200 day MA or 200 week MA could be interesting features later.\n",
    "# features must be unique to each sample (using macro data like inflation would cause model to overfit to one specific instance in history, since the data will be the same for each ticker)\n",
    "# yahooquery priceHistory is sorted by date already, but add tests for this later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "other ways to transform data:\n",
    "%change day to day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalDays = 40\n",
    "trainDays = 30\n",
    "testDays = totalDays - trainDays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7690\n"
     ]
    }
   ],
   "source": [
    "tickers = ['SPY', 'AAPL', 'SNAP', 'TSLA']\n",
    "dfs = []\n",
    "for ticker in tickers:\n",
    "    priceHistory = yahooquery.Ticker(ticker, asnychronous=True)\n",
    "    df = priceHistory.history(period='max', interval='1d')\n",
    "    df = df.dropna()\n",
    "    for col in ['date','high', 'low','adjclose','dividends', 'splits']:\n",
    "        if col in df.columns:\n",
    "            df.drop(col, axis=1, inplace=True)\n",
    "    dfs.append(df)\n",
    "\n",
    "    # TODO: if splits, separate into 2 different dfs. no samples should overlap a split.\n",
    "\n",
    "print(len(dfs[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data 0-1\n",
    "sc_price = MinMaxScaler()\n",
    "sc_volume = MinMaxScaler()\n",
    "for df in dfs:\n",
    "    df[['open', 'close']] = sc_price.fit_transform(df[['open','close']])\n",
    "    df[['volume']] = sc_price.fit_transform(df[['volume']])\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
    "# use inverse_transform to interpret predictions later\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# separate priceHistories into 40 days chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582\n"
     ]
    }
   ],
   "source": [
    "# combine all tickers into 40 day chunks\n",
    "windows = []\n",
    "for df in dfs:\n",
    "    for i in range(df['close'].count() // totalDays): # 30 market days training, 10 market days testing\n",
    "        windows.append(df.iloc[i*totalDays : (i+1)*totalDays])\n",
    "\n",
    "print(len(windows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582\n",
      "40\n",
      "(582, 30, 3)\n",
      "(582, 10, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "windowsValues = [df.values for df in windows] \n",
    "# float 32 is default ^, can reduce open and close to 16 if not normalizing later\n",
    "print(len(windowsValues))\n",
    "print(len(windowsValues[0]))\n",
    "\n",
    "\n",
    "# # VSTACK puts all data back into shape (N*30, 3) for X and (N*10, 3) for Y. not what we want.\n",
    "# X = np.vstack([arr[ : trainDays] for arr in windowsValues]) # vstack concatenates along first axis, turning (N,) into (1,N)\n",
    "# Y = np.vstack([arr[trainDays : ] for arr in windowsValues])\n",
    "# print(X.shape)\n",
    "# print(Y.shape)\n",
    "\n",
    "\n",
    "# split 30 into X and 10 into Y for each window\n",
    "X = np.array([arr[ : trainDays] for arr in windowsValues]) # vstack concatenates along first axis, turning (N,) into (1,N)\n",
    "Y = np.array([arr[trainDays : ] for arr in windowsValues])\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "trainX_tensor = torch.Tensor(X_train)\n",
    "trainY_tensor = torch.Tensor(Y_train)\n",
    "testX_tensor = torch.Tensor(X_test)\n",
    "testY_tensor = torch.Tensor(Y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(trainX_tensor, trainY_tensor)\n",
    "test_data = TensorDataset(testX_tensor, testY_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=5, shuffle=True) # shuffle since samples are taken sequentially but should be evaluated without patterns in the sequence.\n",
    "test_loader = DataLoader(test_data, batch_size=5, shuffle=False) # doesn't change model so don't need to shuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
